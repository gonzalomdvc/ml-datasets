{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1b414eb0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.compose\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import classification_report,f1_score,precision_score,recall_score,roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "id": "1b414eb0"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "12c6a4f5"
      },
      "outputs": [],
      "source": [
        "def load_data(path, partition=0.3):\n",
        "  # permite cargar train, validation y test data. \n",
        "    if path in ('train', 'validation'):\n",
        "        df = pd.read_csv('https://raw.githubusercontent.com/gonzalomdvc/ml-datasets/master/train.csv')\n",
        "        train, valid = train_test_split(df, test_size=partition)\n",
        "    if path == 'train':\n",
        "        x = train.drop(columns=['Credit_Score'])\n",
        "        y = train['Credit_Score']\n",
        "        return x, y\n",
        "    elif path == 'validation':\n",
        "        x = valid.drop(columns=['Credit_Score'])\n",
        "        y = valid['Credit_Score']\n",
        "        return x, y\n",
        "    elif path == 'test':\n",
        "        test = pd.read_csv('https://raw.githubusercontent.com/gonzalomdvc/ml-datasets/master/test.csv')\n",
        "        return test"
      ],
      "id": "12c6a4f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmKKDvqCU47Q"
      },
      "source": [
        "#Preprocesamiento"
      ],
      "id": "hmKKDvqCU47Q"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bZG9uRoQU-Cr"
      },
      "outputs": [],
      "source": [
        "#Type_of_Loan(13) la dropeo, pero se puede hacer un oneHotEncoderManual\n",
        "drop_columns = [0,1,3,5,13]\n",
        "column_transformerX = sklearn.compose.ColumnTransformer(transformers=[    \n",
        "    (\"drop\", \"drop\" , [0,1,3,5,13]),  #borramos todas las columnas que no nos aportan ninguna información \n",
        "    (\"Month\", sklearn.preprocessing.StandardScaler() , [2]),  \n",
        "    (\"Age\", sklearn.preprocessing.StandardScaler() , [4]),  \n",
        "    (\"Trabajo\", sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore') , [6]),#El handle_unknown='ignore' hace que se omita la asignacion de un elemento al encontrar un valor desconocido  \n",
        "    (\"IngresosAnuales\", sklearn.preprocessing.StandardScaler() , [7]),  \n",
        "    (\"SalarioMensual\", sklearn.preprocessing.StandardScaler() , [8]),  \n",
        "    (\"Num_Bank_Accounts\", sklearn.preprocessing.StandardScaler() , [9]),  \n",
        "    (\"Num_Credit_Card\", sklearn.preprocessing.StandardScaler() , [10]),  \n",
        "    (\"Interest_Rate\", sklearn.preprocessing.StandardScaler() , [11]),  \n",
        "    (\"Num_of_Loan\", sklearn.preprocessing.StandardScaler() , [12]),  \n",
        "    (\"Delay_from_due_date\", sklearn.preprocessing.StandardScaler() , [14]),  \n",
        "    (\"Num_of_Delayed_Payment\", sklearn.preprocessing.StandardScaler() , [15]),  \n",
        "    (\"Changed_Credit_Limit\", sklearn.preprocessing.StandardScaler() , [16]),  \n",
        "    (\"Num_Credit_Inquiries\", sklearn.preprocessing.StandardScaler() , [17]),  \n",
        "    (\"Credit_Mix\", sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore') , [18]),\n",
        "    (\"Outstanding_Debt\", sklearn.preprocessing.StandardScaler() , [19]),  \n",
        "    (\"Credit_Utilization_Ratio\", sklearn.preprocessing.StandardScaler() , [20]),  \n",
        "    (\"Credit_History_Age\", sklearn.preprocessing.StandardScaler() , [21]),  \n",
        "    (\"Payment_of_Min_Amount\", sklearn.preprocessing.OneHotEncoder() , [22]),\n",
        "    (\"Total_EMI_per_month\", sklearn.preprocessing.StandardScaler() , [23]),  \n",
        "    (\"Amount_invested_monthly\", sklearn.preprocessing.StandardScaler() , [24]),  \n",
        "    (\"Payment_Behaviour\", sklearn.preprocessing.OneHotEncoder() , [25]),  \n",
        "    (\"Monthly_Balance\", sklearn.preprocessing.StandardScaler() , [26]),  \n",
        "]);"
      ],
      "id": "bZG9uRoQU-Cr"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b1b61184"
      },
      "outputs": [],
      "source": [
        "def fit_knn(x, y, params):\n",
        "  # implementa knn con key word args\n",
        "    clf = GridSearchCV(KNeighborsClassifier(), params, scoring='f1_macro')\n",
        "    return clf.fit(x, y)"
      ],
      "id": "b1b61184"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2b2227fa"
      },
      "outputs": [],
      "source": [
        "def eval_classifier(classifier, x_valid, y_valid, y_pred):\n",
        "  # nos da las medidas recall, precision, f1 y una matriz de confusión. En principio vale para cualquier clasificador\n",
        "    print(classification_report(y_pred, y_valid))\n",
        "    plot_confusion_matrix(classifier, x_valid, y_valid, display_labels=set(y_valid.values), cmap=plt.cm.Blues)"
      ],
      "id": "2b2227fa"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "db9f871a"
      },
      "outputs": [],
      "source": [
        "#provisional: dejar sólo datos numéricos\n",
        "x, y = load_data('train')\n",
        "x = pd.DataFrame(column_transformerX.fit_transform(x))\n",
        "x_valid, y_valid = load_data('validation')\n",
        "x_valid = pd.DataFrame(column_transformerX.fit_transform(x_valid))"
      ],
      "id": "db9f871a"
    },
    {
      "cell_type": "code",
      "source": [
        "knn_params = {\n",
        "    \"n_neighbors\": list(range(4, 8)),\n",
        "    \"weights\": ['uniform', 'distance'],\n",
        "}"
      ],
      "metadata": {
        "id": "NypEosa6GmJ0"
      },
      "id": "NypEosa6GmJ0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eb3a978"
      },
      "outputs": [],
      "source": [
        "# se llama a la función de knn usando keyword args (podemos hacer una función que instancie varios classifiers con distintos parámetros)\n",
        "classifier_1 = fit_knn(x, y, knn_params)"
      ],
      "id": "1eb3a978"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_1.best_params_"
      ],
      "metadata": {
        "id": "VH01_DFQRtJ1"
      },
      "id": "VH01_DFQRtJ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier_1.predict(x_valid)\n",
        "eval_classifier(classifier_1, x_valid, y_valid, y_pred) "
      ],
      "metadata": {
        "id": "g6LR6EoxLJ2U"
      },
      "id": "g6LR6EoxLJ2U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06mjFZ6VYVU6"
      },
      "outputs": [],
      "source": [
        "x_test = load_data('test')\n",
        "x_ids = x_test['ID'].values\n",
        "x_test = pd.DataFrame(column_transformerX.fit_transform(x_test))\n",
        "pred = classifier_1.predict(x_test)\n",
        "results = pd.DataFrame(list(zip(x_ids, pred)), columns=['ID', 'Credit_Score'])"
      ],
      "id": "06mjFZ6VYVU6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbmLGmtTZDxu"
      },
      "outputs": [],
      "source": [
        "results.to_csv('predictions.csv', index=False)"
      ],
      "id": "sbmLGmtTZDxu"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nlp_1",
      "language": "python",
      "name": "nlp_1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}